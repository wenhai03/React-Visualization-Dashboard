const en_US = {
  copy: 'Copy JSON to clipboard',
  row_height: 'Row Height',
  query_btn: 'Execute',
  application_log: 'Application log',
  host_log: 'Host log',
  POD_log: 'POD log',
  container_log: 'Container log',
  syslog: 'Syslog',
  optional_index: 'Optional index',
  optional_view: 'Optional view',
  service_name: 'Service name',
  service_environment: 'Service environment',
  host: 'Host',
  pod_name: 'POD name',
  cluster_name: 'Cluster name',
  container_name: 'Container name',
  container_id: 'Container ID',
  device_IP: 'Device IP',
  group_cluster: 'Service group cluster',
  required_ip: 'The device IP address cannot be empty',
  serviceName: 'Service',
  data_view: 'Data view',
  collector_log: 'Collector log',
  k8s_event: 'k8s event log',
  host_port: 'Port',
  host_ip: 'IP',
  req_client_ip: 'Client ip',
  upstream_time: 'Upstream time',
  resp_time: 'Network delay (>N seconds)',
  keyword: 'keyword',
  keyword_placeholder: 'ou can enter multiple keywords and press enter for segmentation',
  req_url: 'Request URL',
  java_log: 'Java logs',
  nginx_log: 'Nginx logs',
  erp_log: {
    req_clientip: 'Client ip',
    resp_time: 'Response time',
    upstream_time: 'Server response time',
    network_delay: 'Network delay',
    resp_status: 'Status code',
    resp_bytes: 'Number of bytes',
  },
  explorer: {
    title: 'Log Query',
    erp_title: 'ERP log Query',
    doc: 'Document',
    single: 'Single',
    auto: 'Auto fit',
    custom: 'Custom',
    unable_parse: 'Unable to parse',
    hits: '{{num}} hits',
    detail: 'Log detail',
    row_num: 'Lines per row',
    interval: 'Interval',
    custom_column_tip: 'When no field is selected, @timestamp and document are displayed by default',
    dial_search: 'Dial Query',
    address: 'Address',
    fail_reason: 'Fail reason',
    log_export: 'Log export',
  },
  stream: {
    title: 'Log flow',
    font_size: 'Font Size',
    large: 'Large',
    medium: 'Medium',
    small: 'Small',
    custom: 'Custom',
    highlight: 'Highlight',
    required_highlight: 'Please enter the words you want to highlight',
    real_time_streaming: 'Real-time streaming',
    stop_streaming: 'Stop Real-time streaming',
    message: 'Message',
    display_column: 'Display column',
    service: {
      name: 'Service name',
      environment: 'Service environment',
    },
    log: {
      level: 'Log level',
    },
    reason: 'Reason',
    type: 'Type',
    involvedObject: {
      kind: 'Resource Kind',
      name: 'Resource name',
    },
    ident: 'Ident',
    unit: 'Unit',
    fields: {
      kubernates: {
        pod_name: 'POD name',
      },
      docker: {
        container_name: 'Docker',
      },
    },
    'service.name': 'Service name',
    'service.environment': 'Service environment',
    'log.level': 'Log level',
    'fields.kubernates.pod_name': 'POD name',
    'fields.docker.container_name': 'Docker',
    'event.type': 'Event type',
    'event.reason': 'Event reason',
    'event.involvedObject.kind': 'Resource Kind',
    'event.involvedObject.name': 'Resource name',
    'event.message': 'Resource message',
  },
  task: {
    title: 'Log Collection',
    consumer_threads: 'Consumer Threads',
    log_source: 'Log source',
    basic_setting: 'Basic configuration',
    from_server: 'Collection from host',
    from_docker: 'Collection from docker',
    choose_from: 'Choose which one?',
    choose_from_tip: `choose from docker when deploy in k8s,
otherwise chhose from host.`,
    from_docker_tip:
      'cndgraf/logs.items.*** Indicates the configuration of log collection items. *** is the corresponding topic for kafka, which has the same value as the topic = "cndgraf" configuration in the configuration content',
    access_target: 'Save target',
    access_data_source: 'Save data source',
    workers: 'Pipeline worker thread',
    workers_num: 'Number of channels',
    workers_num_tip: `The number of channels that the task runs on each vector instance. The default is 1.
It is usually left as default, and vector performs very well. Adjustments are required only when large amounts of data need to be processed, such as hundreds of thousands per second.`,
    batch_size: 'Manage batch size',
    batch_delay: 'Pipeline batch delay',
    status: 'Status',
    default_set_btn: 'Default configuration',
    create: 'Creating a log task',
    edit: 'Edit log task',
    name: 'Task Name',
    ident_tip:
      'Contains only lowercase letters, digits, hyphens and underscores, must be unique within 32 characters, will be used as the kafka topic name, cannot be modified after approval',
    ident_required: 'The value contains a maximum of 32 lowercase letters, digits, hyphens (-), and underscores (_)',
    filter_rule: 'pipeline',
    set: 'Set',
    host: 'Host',
    mode: 'Mode',
    all_host: 'All host',
    current_group: 'Current business group',
    log_collection: 'Log collection configuration',
    type: 'Type',
    type_file: 'collect from file',
    type_journald: 'collect from journald',
    container_file: 'Collect the log files in the container',
    container_name: 'Container name',
    container_name_tip: 'Support for regular',
    rule: 'Processing rule',
    rule_type: 'Rule type',
    replace_placeholder: 'Replace placeholder',
    pattern: 'Pattern',
    file_path: 'File path',
    file_path_tip: 'absolute path, support global wildcard, such as:/var/log/*.log',
    file_encoding_tip: 'file encoding, usually UTF8',
    journald_path: 'Directory path of journald',
    default_content: 'Default file content',
    multi_line: 'Merger rule',
    include_at_match: 'Inclusion rule list',
    exclude_at_match: 'Exclusion rule list',
    mask_sequences: 'Substitution rule',
    custom_tags: 'Custom fields(such as: type,service_name,service_environment)',
    custom_tags_tip: 'Add the log content to identify the log source information',
    coding_rule: 'Coding rule',
    exclude_paths: 'Exclude the file path list',
    exclude_paths_tip: 'support global wildcard, support multiple paths',
    file_start_position_tip: 'If the file path contains wildcard, only read file from end',
    start_mode: 'Initial tailing position',
    start_begin: 'from file header the first time',
    start_end: 'from file tail the first time',
    start_force_begin: 'from file header *every* time',
    start_force_end: 'from file tail *every* time',
    include_unit: 'Include units list',
    exclude_unit: 'Exclude units list',
    merge_multiple: 'Automatically merge multiple rows',
    auto_multiline_tip: `auto merge muline if starts with common date format
In particular, if type='java', the automatic line break will start with the timestamp '2020-01-01 00:00:00.000'
If automatic merging is enabled and merging rules are manually added, the manual rules will prevail`,
    ignore_missing: 'Ignore file does not exist errors',
    ignore_missing_tip: 'If checked, error logs indicating that the file path does not exist will not be printed.',
    rule_type_tip: `Merge rule (multi_line) : Merge multiple lines that match the rule into one line
Include rule (include_at_match) : Collect only the log rows that match the rule
Exclusion rule (exclude_at_match) : The log rows that match the rule are not collected
Replace sequences (mask_sequences) : Replace log content that matches the rules`,
    rule_pattern_tip:
      'Support for regular patterns, such as matching strings starting with 2023/09/01, the pattern can be written as follows: ^d{4}/d{2}/d{2}',
    copy: 'copy',
    note: 'Note ',
    public_task: 'Common task',
    is: 'Is',
    no: 'No',
    write_type: 'Write type',
    custom: 'Custom',
    public_id: 'Associated public task',
    create_template: 'Create a template',
    template: 'Select template',
    template_name: 'Template name',
    template_note: 'Template note',
    default_template: 'Default template',
    search: 'Search',
    search_tip: 'Query other tasks associated with this task',
    log_task: 'Log task',
    auto_multi_line_detection_tip: 'Auto merge cannot be selected when multiline is selected as the processing rule.',
    pattern_requied: 'Please enter a rule mode',
    rule_type_requied: 'Please select a rule type',
    delete_ing_tip: 'deleting',
    ident_rule: 'Ident rule',
    ident_rule_tip:
      'Restricting the associated task identification rules and using regular expressions;such as ^applog-.*$ , The restriction rule must start with applog-',
    processor: 'Processor',
    container: 'Run on the container',
    content_detection: 'toml detection tool',
    content_detection_tip:
      'This tool is used to detect whether toml content is legitimate, such as missing required fields or syntax errors.',
    novice_config: 'Novice configuration tool',
    common_rule: 'Common processing rule',
    common_rule_alert: 'Public processing rules take effect automatically only when the server files are collected',
    collect_object: 'Acquisition object',
    config_exception: 'Configuration exception',
    relevance_host: 'Relevance host',
    content: 'Content',
    copy_tip: '(Click to copy)',
    verify: 'Verify',
    topic_name: 'Topic name',
    verify_result: 'Verify result',
    success: 'Success',
    build_configuration: 'Build configuration',
    config_result: 'Configuration result',
    topic_tip: 'Please fill in the task ID first',
    shield_ident: 'Shielding ident',
    topic: 'Topic',
    hash: 'Hash',
    shield_success: 'Shield success',
    shield: 'Shield',
    collection_type: 'Collection type',
    vector_validate: 'vector verification',
    vector_vrl: 'vector debugging',
    vector_vrl_tip: 'VRL syntax debugging',
    vector_validate_tip: 'Run the vector validate command to verify that the pipeline is valid',
    logstash_deprecated: 'Deprecated',
    logstash_deprecated_tip: 'Logstash is deprecated due to low performance and maintaince, prefer vector.',
    os: 'Os',
    os_placeholder: 'If no value is specified, all operating systems are included',
    rt: 'Run container',
    rt_placeholder: 'If no value is specified, all environments are included',
    binding_template: 'Binding template:',
    tpl_not_exist: 'The template does not exist. The code is',
    conduit_type: 'Pipeline type',
    ref_template: 'Reference template',
  },
  management: {
    title: 'logstash Management',
    logstash_ident: 'logstash service identifier',
    enable: 'enable',
    disable: 'disable',
    reviewed: 'To be reviewed',
  },
  template: {
    title: 'ES Template',
    content: 'Content',
    default: 'ES Default Template',
    index_patterns: 'Index patterns',
    version: 'Template version',
    old: 'Old version',
    new: 'New version',
    data_stream: 'Data stream',
    roll: 'Rollover',
    rollover: 'Rollover result',
    rolloverTip: 'Execute rollover asynchronously. Please refresh the query results after modification.',
    preview: 'Preview',
    success: 'Success',
    fail: 'Fail',
    not_run: 'Not run',
    cost: 'time-consuming',
    result: 'Result',
    running: 'In operation',
    run_tooltip: 'Confirm running',
    run: 'Run',
    search_placeholder: 'Enter the index pattern and data stream to search',
    status_placeholder: 'Selective state',
  },
  field: {
    boolean: 'Boolean value field',
    conflict: 'Conflicting field',
    date: 'Date field',
    date_range: 'Date range field',
    geo_point: 'Geographic point field',
    geo_shape: 'Geometry field',
    ip: 'IP address field',
    ip_range: 'IP range field',
    match_only_text: 'Text field',
    murmur3: 'Murmur3 field',
    number: 'Numeric field',
    number_range: 'Numeric range field',
    histogram: 'Histogram field',
    _source: 'Source field',
    string: 'String field',
    text: 'Text field',
    keyword: 'Keyword field',
    nested: 'Nested field',
    version: 'Version field',
  },
};
export default en_US;
